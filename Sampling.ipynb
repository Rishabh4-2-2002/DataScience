{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad3695b",
   "metadata": {},
   "source": [
    "# Sampling assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9d04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5ff94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066ecf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>575</td>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143508</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>579</td>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071270</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>579</td>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>580</td>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164468</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>581</td>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107809</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n",
       "768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n",
       "769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n",
       "770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n",
       "771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0    0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1   -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2    0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3    0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4    0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767  1.084879 -0.146329 -0.274447  ... -0.143508 -0.107582 -0.418263   \n",
       "768 -0.173310  0.260423 -1.202688  ... -0.071270 -0.161175  0.088496   \n",
       "769  0.021782 -0.106888 -0.037631  ... -0.224292 -0.594609  0.159877   \n",
       "770 -0.226582  0.109483  0.657565  ... -0.164468 -0.177225 -0.222918   \n",
       "771  0.020653  0.029260  0.412254  ... -0.107809 -0.125231 -0.057041   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0    0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1   -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2   -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3   -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4    0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "767 -0.731029  0.877525 -0.364150 -0.177509 -0.256545   26.72      0  \n",
       "768  0.285390  0.281069 -0.370130  0.043410  0.092318   80.00      0  \n",
       "769  0.091873  0.140964  0.227406 -0.017389  0.016030    5.98      0  \n",
       "770 -1.245505  0.678360  0.525059  0.002920 -0.003333   12.36      0  \n",
       "771  0.073082  0.633977 -0.310685  0.033590  0.015250   13.79      0  \n",
       "\n",
       "[772 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6fd1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Class\"]\n",
    "X = data[data.columns.drop(\"Class\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34d4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ecd2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eea27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72dd5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c1f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1    763\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c089b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1      9\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f18a4",
   "metadata": {},
   "source": [
    "## creating random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f245ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random sampling\n",
    "sample_size = 100  # desired sample size\n",
    "x_s1 = x_smote.sample(n=sample_size, random_state=42)  # random sampling with seed 42\n",
    "y_s1 = y_smote.sample(n=sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b3ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time        V1        V2        V3        V4        V5        V6  \\\n",
      "1439   510 -1.567349 -1.326610  2.173881  0.753328  1.857867 -0.009737   \n",
      "76      49 -0.549626  0.418949  1.729833  0.203065 -0.187012  0.253878   \n",
      "1010   131  0.904835  0.409773  0.346759  0.521796 -0.017539 -0.678598   \n",
      "660    499  1.255439  0.307729  0.292700  0.699873 -0.428876 -1.088456   \n",
      "1132   538 -0.251057 -0.870708  0.581068  1.251179  0.244699 -1.066549   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "988    494 -2.088680 -1.238085  1.314492  1.948031  1.618312  0.022936   \n",
      "570    427 -0.847312  0.854261  0.338816  0.890137  0.804751  1.165501   \n",
      "1124   448 -1.543446 -1.824035  2.022988  0.914124  2.100762  0.518713   \n",
      "1163   143  0.590687  0.463152  0.386486  0.368062  0.300065 -0.327138   \n",
      "654    495 -0.239505 -3.940241 -0.147576 -0.671347 -2.239256  0.908178   \n",
      "\n",
      "            V7        V8        V9  ...       V20       V21       V22  \\\n",
      "1439 -0.902724  0.406649  0.514100  ...  0.322313  0.278609  0.826185   \n",
      "76    0.500894  0.251256 -0.227985  ...  0.016970  0.115062  0.418529   \n",
      "1010  0.148871 -0.101395 -0.011725  ... -0.069137 -0.240526 -0.699115   \n",
      "660   0.043840 -0.167739  0.128854  ... -0.121156 -0.294795 -0.882126   \n",
      "1132  0.175407 -0.160313 -0.085659  ...  0.689550  0.045873 -0.380036   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "988  -2.230963  0.958916 -0.095432  ...  0.481237  0.449249  0.847521   \n",
      "570  -0.081408  0.879014 -0.394737  ...  0.081904 -0.046690 -0.075301   \n",
      "1124 -1.579792  0.645341  0.720369  ...  0.474373  0.300966  0.847753   \n",
      "1163  0.204589 -0.010366 -0.053793  ... -0.059608 -0.198291 -0.579258   \n",
      "654  -0.377398  0.157943 -1.595928  ...  1.217690  0.076296 -1.132178   \n",
      "\n",
      "           V23       V24       V25       V26       V27       V28      Amount  \n",
      "1439  0.073325 -0.355213  0.027259  0.329889 -0.116473 -0.152764    1.298030  \n",
      "76   -0.065133  0.264981  0.003958  0.395969  0.027182  0.043506   59.990000  \n",
      "1010  0.134877 -0.165325 -0.259658  0.088987  0.052238  0.089942    2.186254  \n",
      "660   0.136846  0.327949  0.194459  0.096516 -0.027271  0.029491    1.980000  \n",
      "1132  0.565537  0.119708  0.241703  0.010292 -0.103072  0.032635  186.397736  \n",
      "...        ...       ...       ...       ...       ...       ...         ...  \n",
      "988   0.082106 -0.524255 -0.144728  0.667869 -0.015557 -0.163205    1.075917  \n",
      "570  -0.308479 -1.733137  0.087036 -0.129209  0.294334  0.071198   11.360000  \n",
      "1124  0.265476 -0.968817 -0.477135  0.687872 -0.046078 -0.082629    1.387596  \n",
      "1163  0.140974 -0.618270 -0.686446  0.083857  0.120072  0.142932    1.734212  \n",
      "654  -0.486820 -0.302911 -0.304121 -0.469811 -0.077517  0.151745  834.840000  \n",
      "\n",
      "[100 rows x 30 columns] 1439    1\n",
      "76      0\n",
      "1010    1\n",
      "660     0\n",
      "1132    1\n",
      "       ..\n",
      "988     1\n",
      "570     0\n",
      "1124    1\n",
      "1163    1\n",
      "654     0\n",
      "Name: Class, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_s1,y_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d179a984",
   "metadata": {},
   "source": [
    "## systematic sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d835765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time        V1        V2        V3        V4        V5        V6  \\\n",
      "5        2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
      "20      16  0.694885 -1.361819  1.029221  0.834159 -1.191209  1.309109   \n",
      "35      26 -0.535388  0.865268  1.351076  0.147575  0.433680  0.086983   \n",
      "50      35  1.199356  0.129953  0.863585  1.002635 -0.783761 -0.884679   \n",
      "65      44 -0.899992  0.136255  1.883665 -0.208996  1.051441  1.905241   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "1460   473 -0.867667  0.396868  1.701313  0.196801  0.929358 -0.905688   \n",
      "1475   145  0.538435  0.472031  0.393094  0.342491  0.352893 -0.268679   \n",
      "1490   534 -1.858741 -1.116000  1.774169  0.167404  1.627578  0.114598   \n",
      "1505     0  1.185846  0.267682  0.168014  0.446363  0.064118 -0.080566   \n",
      "1520   560  0.269979 -0.502329  0.961789  0.826877  0.497023 -0.563729   \n",
      "\n",
      "            V7        V8        V9  ...       V20       V21       V22  \\\n",
      "5     0.476201  0.260314 -0.568671  ...  0.084968 -0.208254 -0.559825   \n",
      "20   -0.878586  0.445290 -0.446196  ... -0.138334 -0.295583 -0.571955   \n",
      "35    0.693039  0.179742 -0.285642  ... -0.283264  0.049526  0.206537   \n",
      "50   -0.040743 -0.208069  0.392478  ... -0.072620 -0.042468  0.198474   \n",
      "65    0.241423  0.647631 -0.053466  ... -0.121726 -0.081500 -0.016926   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1460  0.857089 -0.157870 -0.137211  ... -0.117217  0.056557  0.250543   \n",
      "1475  0.213857  0.004775 -0.060790  ... -0.058023 -0.191266 -0.559321   \n",
      "1490 -0.822164  0.437705  0.452459  ...  0.286385  0.096560  0.444307   \n",
      "1505 -0.076787  0.085394 -0.254714  ... -0.068948 -0.225254 -0.637292   \n",
      "1520 -0.574002  0.092437  0.300733  ...  0.136811 -0.071831 -0.209498   \n",
      "\n",
      "           V23       V24       V25       V26       V27       V28      Amount  \n",
      "5    -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.670000  \n",
      "20   -0.050881 -0.304215  0.072001 -0.422234  0.086553  0.063499  231.710000  \n",
      "35   -0.187108  0.000753  0.098117 -0.553471 -0.078306  0.025427    1.770000  \n",
      "50   -0.033010  1.013290  0.559098  0.401818 -0.005865  0.017936    0.990000  \n",
      "65   -0.147706 -1.384620 -0.024352  0.412659 -0.106776 -0.190476   21.550000  \n",
      "...        ...       ...       ...       ...       ...       ...         ...  \n",
      "1460 -0.247281  0.384112  0.386269 -0.438671 -0.102204 -0.121429    1.046775  \n",
      "1475  0.141988 -0.693609 -0.757434  0.083004  0.131355  0.151746    1.659022  \n",
      "1490 -0.005167 -0.521668 -0.281966  0.525004 -0.243994 -0.286099    1.229324  \n",
      "1505  0.101555 -0.345351  0.158806  0.125623 -0.007689  0.015882    2.680863  \n",
      "1520  0.179251 -0.020719  0.087601  0.326792 -0.053241 -0.030293    1.353661  \n",
      "\n",
      "[102 rows x 30 columns] 5       0\n",
      "20      0\n",
      "35      0\n",
      "50      0\n",
      "65      0\n",
      "       ..\n",
      "1460    1\n",
      "1475    1\n",
      "1490    1\n",
      "1505    1\n",
      "1520    1\n",
      "Name: Class, Length: 102, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the sampling interval\n",
    "interval = mt.floor(x_smote.shape[0]/100)\n",
    "# Determine the starting point\n",
    "start = 5\n",
    "# Perform systematic sampling\n",
    "x_s2 = x_smote.iloc[start::interval]\n",
    "y_s2 = y_smote.iloc[start::interval]\n",
    "# View the sampled data\n",
    "print(x_s2,y_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d5d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb86fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.005181</td>\n",
       "      <td>-0.176963</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.875172</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.159081</td>\n",
       "      <td>0.123329</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>-0.096995</td>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>0.114337</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>68.668290</td>\n",
       "      <td>0.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.834196</td>\n",
       "      <td>1.294724</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>1.031878</td>\n",
       "      <td>1.258758</td>\n",
       "      <td>1.098143</td>\n",
       "      <td>1.225682</td>\n",
       "      <td>0.852075</td>\n",
       "      <td>0.830144</td>\n",
       "      <td>0.878183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609335</td>\n",
       "      <td>0.607228</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.621507</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.300934</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>197.838269</td>\n",
       "      <td>0.107411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.093248</td>\n",
       "      <td>-12.114213</td>\n",
       "      <td>-5.694973</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-6.631951</td>\n",
       "      <td>-3.498447</td>\n",
       "      <td>-4.925568</td>\n",
       "      <td>-7.494658</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.134608</td>\n",
       "      <td>-2.776923</td>\n",
       "      <td>-3.553381</td>\n",
       "      <td>-1.867208</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>-1.243924</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-2.735623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>-0.896416</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>-0.460058</td>\n",
       "      <td>-0.534567</td>\n",
       "      <td>-0.630717</td>\n",
       "      <td>-0.296289</td>\n",
       "      <td>-0.167880</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213746</td>\n",
       "      <td>-0.525289</td>\n",
       "      <td>-0.176915</td>\n",
       "      <td>-0.379766</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>-0.313631</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-0.033083</td>\n",
       "      <td>5.987500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>-0.382618</td>\n",
       "      <td>0.285843</td>\n",
       "      <td>0.905435</td>\n",
       "      <td>0.395919</td>\n",
       "      <td>-0.116612</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-0.082270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075802</td>\n",
       "      <td>-0.076551</td>\n",
       "      <td>-0.048353</td>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>-0.026414</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>432.000000</td>\n",
       "      <td>1.110739</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>1.532969</td>\n",
       "      <td>1.117559</td>\n",
       "      <td>0.452818</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.425798</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.112199</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>55.527500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581.000000</td>\n",
       "      <td>1.586093</td>\n",
       "      <td>5.267376</td>\n",
       "      <td>3.772857</td>\n",
       "      <td>4.075817</td>\n",
       "      <td>7.672544</td>\n",
       "      <td>5.122103</td>\n",
       "      <td>4.808426</td>\n",
       "      <td>2.134599</td>\n",
       "      <td>5.459274</td>\n",
       "      <td>...</td>\n",
       "      <td>5.273420</td>\n",
       "      <td>1.574750</td>\n",
       "      <td>3.150413</td>\n",
       "      <td>1.215279</td>\n",
       "      <td>1.136720</td>\n",
       "      <td>3.087444</td>\n",
       "      <td>2.490503</td>\n",
       "      <td>1.575380</td>\n",
       "      <td>3828.040000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time          V1          V2          V3          V4          V5  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
       "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
       "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
       "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
       "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
       "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
       "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
       "\n",
       "               V6          V7          V8          V9  ...         V21  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
       "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
       "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
       "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
       "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
       "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
       "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
       "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
       "\n",
       "              V22         V23         V24         V25         V26         V27  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
       "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
       "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
       "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
       "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
       "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
       "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
       "\n",
       "              V28       Amount       Class  \n",
       "count  772.000000   772.000000  772.000000  \n",
       "mean    -0.017045    68.668290    0.011658  \n",
       "std      0.278332   197.838269    0.107411  \n",
       "min     -2.735623     0.000000    0.000000  \n",
       "25%     -0.033083     5.987500    0.000000  \n",
       "50%      0.021034    16.665000    0.000000  \n",
       "75%      0.087023    55.527500    0.000000  \n",
       "max      1.575380  3828.040000    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab576ca",
   "metadata": {},
   "source": [
    "## stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3de63da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s3_0=x_smote[y_smote.iloc[:]==0]\n",
    "x_s3_1=x_smote[y_smote.iloc[:]==1]\n",
    "y_s3_0=y_smote[y_smote.iloc[:]==0]\n",
    "y_s3_1=y_smote[y_smote.iloc[:]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad66e3b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/588nflw97fjflys51trjr2g40000gn/T/ipykernel_23817/3050891127.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  x_s3=x_s3.append(x_s3_1.sample(50,random_state=42))\n",
      "/var/folders/w7/588nflw97fjflys51trjr2g40000gn/T/ipykernel_23817/3050891127.py:4: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_s3=y_s3.append(y_s3_1.sample(50,random_state=42))\n"
     ]
    }
   ],
   "source": [
    "x_s3=x_s3_0.sample(50,random_state=42)\n",
    "x_s3=x_s3.append(x_s3_1.sample(50,random_state=42))\n",
    "y_s3=y_s3_0.sample(50,random_state=42)\n",
    "y_s3=y_s3.append(y_s3_1.sample(50,random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4231531",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df314c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "cs = []\n",
    "for i in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(x_smote)\n",
    "    cs.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 21), cs)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('CS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdfeaacd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
      "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
      "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
      "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
      "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
      "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
      "\n",
      "        V27       V28  Amount  Class  Cluster  \n",
      "0  0.133558 -0.021053  149.62      0        8  \n",
      "1 -0.008983  0.014724    2.69      1       13  \n",
      "2 -0.055353 -0.059752  378.66      0        4  \n",
      "3  0.062723  0.061458  123.50      0       13  \n",
      "4  0.219422  0.215153   69.99      0       13  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# import numpy as np\n",
    "\n",
    "# # generate some data for clustering\n",
    "\n",
    "\n",
    "# set the number of clusters\n",
    "n_clusters = 14\n",
    "\n",
    "# create KMeans object\n",
    "kmeans = KMeans(n_clusters=n_clusters,random_state=42)\n",
    "\n",
    "# fit the model to the data\n",
    "kmeans.fit(data)\n",
    "\n",
    "\n",
    "# # get the cluster labels for each data point\n",
    "# labels = kmeans.labels_\n",
    "\n",
    "# # get the coordinates of the cluster centers\n",
    "# centers = kmeans.cluster_centers_\n",
    "\n",
    "# print(labels)\n",
    "# print(centers)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# # set the number of clusters\n",
    "# n_clusters = 14\n",
    "\n",
    "# # create KMeans object\n",
    "# kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# # fit the model to the data\n",
    "# kmeans.fit(data)\n",
    "\n",
    "# get the cluster labels for each data point\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# append the cluster labels to the original data\n",
    "cluster_data = pd.DataFrame({'Cluster': labels})\n",
    "\n",
    "# concatenate the original dataframe with the new dataframe containing the cluster labels\n",
    "data_with_clusters = pd.concat([data, cluster_data], axis=1)\n",
    "\n",
    "# print the first few rows of the data with the cluster labels\n",
    "print(data_with_clusters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a321210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>575</td>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>579</td>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>579</td>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>580</td>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>581</td>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n",
       "768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n",
       "769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n",
       "770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n",
       "771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n",
       "\n",
       "           V7        V8        V9  ...       V22       V23       V24  \\\n",
       "0    0.239599  0.098698  0.363787  ...  0.277838 -0.110474  0.066928   \n",
       "1   -0.078803  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846   \n",
       "2    0.791461  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281   \n",
       "3    0.237609  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575   \n",
       "4    0.592941 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767  1.084879 -0.146329 -0.274447  ... -0.107582 -0.418263 -0.731029   \n",
       "768 -0.173310  0.260423 -1.202688  ... -0.161175  0.088496  0.285390   \n",
       "769  0.021782 -0.106888 -0.037631  ... -0.594609  0.159877  0.091873   \n",
       "770 -0.226582  0.109483  0.657565  ... -0.177225 -0.222918 -1.245505   \n",
       "771  0.020653  0.029260  0.412254  ... -0.125231 -0.057041  0.073082   \n",
       "\n",
       "          V25       V26       V27       V28  Amount  Class  Cluster  \n",
       "0    0.128539 -0.189115  0.133558 -0.021053  149.62      0        8  \n",
       "1    0.167170  0.125895 -0.008983  0.014724    2.69      1       13  \n",
       "2   -0.327642 -0.139097 -0.055353 -0.059752  378.66      0        4  \n",
       "3    0.647376 -0.221929  0.062723  0.061458  123.50      0       13  \n",
       "4   -0.206010  0.502292  0.219422  0.215153   69.99      0       13  \n",
       "..        ...       ...       ...       ...     ...    ...      ...  \n",
       "767  0.877525 -0.364150 -0.177509 -0.256545   26.72      0        1  \n",
       "768  0.281069 -0.370130  0.043410  0.092318   80.00      0        1  \n",
       "769  0.140964  0.227406 -0.017389  0.016030    5.98      0        1  \n",
       "770  0.678360  0.525059  0.002920 -0.003333   12.36      0        1  \n",
       "771  0.633977 -0.310685  0.033590  0.015250   13.79      0        1  \n",
       "\n",
       "[772 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bac902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the cluster labels and group the data points by their corresponding cluster label\n",
    "clusters = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05a2d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=list(clusters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91aeb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dictionary of dataframes, one for each cluster\n",
    "cluster_dfs = {}\n",
    "for i, data_with_clusters in data_with_clusters.groupby('Cluster'):\n",
    "    cluster_dfs[i] = pd.DataFrame(data_with_clusters)\n",
    "\n",
    "# access the dataframe for cluster 0\n",
    "# cluster_0_df = cluster_dfs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52e52e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the selected rows\n",
    "selected_rows = []\n",
    "\n",
    "# iterate over the keys of the dictionary\n",
    "for key in cluster_dfs.keys():\n",
    "    # use the sample() method to select 10 random rows from the dataframe\n",
    "    rows = cluster_dfs[key].sample(n=10, random_state=42,replace=True)\n",
    "    # append the selected rows to the list\n",
    "    selected_rows.append(rows)\n",
    "\n",
    "# concatenate the selected rows into a single dataframe\n",
    "selected_df = pd.concat(selected_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a0e5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s4=selected_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ada331eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s4=selected_df[selected_df.columns.drop(\"Cluster\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7511770",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s4=x_s4[x_s4.columns.drop(\"Class\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ed4f5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>142</td>\n",
       "      <td>1.211406</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.950798</td>\n",
       "      <td>1.137646</td>\n",
       "      <td>-0.495189</td>\n",
       "      <td>0.301371</td>\n",
       "      <td>-0.518350</td>\n",
       "      <td>0.095426</td>\n",
       "      <td>0.817592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049912</td>\n",
       "      <td>-0.107248</td>\n",
       "      <td>-0.057153</td>\n",
       "      <td>-0.118933</td>\n",
       "      <td>-0.421241</td>\n",
       "      <td>0.556146</td>\n",
       "      <td>-0.360164</td>\n",
       "      <td>0.076930</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>105</td>\n",
       "      <td>1.175094</td>\n",
       "      <td>0.408263</td>\n",
       "      <td>0.552145</td>\n",
       "      <td>1.255068</td>\n",
       "      <td>-0.196662</td>\n",
       "      <td>-0.565605</td>\n",
       "      <td>0.133973</td>\n",
       "      <td>-0.146202</td>\n",
       "      <td>-0.214155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116439</td>\n",
       "      <td>0.130585</td>\n",
       "      <td>0.523640</td>\n",
       "      <td>-0.050125</td>\n",
       "      <td>0.448133</td>\n",
       "      <td>0.597867</td>\n",
       "      <td>-0.275067</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>0.023924</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>162</td>\n",
       "      <td>1.039964</td>\n",
       "      <td>-0.534355</td>\n",
       "      <td>1.865190</td>\n",
       "      <td>1.145122</td>\n",
       "      <td>-1.488133</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>-1.119900</td>\n",
       "      <td>0.382781</td>\n",
       "      <td>1.419160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053880</td>\n",
       "      <td>-0.014701</td>\n",
       "      <td>0.430843</td>\n",
       "      <td>-0.071344</td>\n",
       "      <td>0.638434</td>\n",
       "      <td>0.366778</td>\n",
       "      <td>0.451211</td>\n",
       "      <td>0.053840</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>147</td>\n",
       "      <td>-2.687978</td>\n",
       "      <td>4.390230</td>\n",
       "      <td>-2.360483</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>-1.645253</td>\n",
       "      <td>2.327776</td>\n",
       "      <td>-1.727825</td>\n",
       "      <td>4.324752</td>\n",
       "      <td>...</td>\n",
       "      <td>3.169344</td>\n",
       "      <td>-1.045961</td>\n",
       "      <td>-0.156951</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>-0.012598</td>\n",
       "      <td>0.207194</td>\n",
       "      <td>-0.536578</td>\n",
       "      <td>0.950393</td>\n",
       "      <td>-0.624431</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>112</td>\n",
       "      <td>1.102698</td>\n",
       "      <td>0.103965</td>\n",
       "      <td>0.934479</td>\n",
       "      <td>1.152704</td>\n",
       "      <td>-0.693597</td>\n",
       "      <td>-0.584580</td>\n",
       "      <td>-0.148439</td>\n",
       "      <td>-0.112031</td>\n",
       "      <td>0.196750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>-0.017211</td>\n",
       "      <td>-0.098781</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.394412</td>\n",
       "      <td>0.334208</td>\n",
       "      <td>-0.520700</td>\n",
       "      <td>0.045952</td>\n",
       "      <td>0.048005</td>\n",
       "      <td>54.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>0.247491</td>\n",
       "      <td>0.277666</td>\n",
       "      <td>1.185471</td>\n",
       "      <td>-0.092603</td>\n",
       "      <td>-1.314394</td>\n",
       "      <td>-0.150116</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-1.617935</td>\n",
       "      <td>1.544071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230983</td>\n",
       "      <td>1.650180</td>\n",
       "      <td>0.200454</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>-0.227632</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.250475</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>74</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335520</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>83</td>\n",
       "      <td>-1.864990</td>\n",
       "      <td>0.910874</td>\n",
       "      <td>1.724863</td>\n",
       "      <td>-1.748371</td>\n",
       "      <td>0.578943</td>\n",
       "      <td>-0.832531</td>\n",
       "      <td>1.901440</td>\n",
       "      <td>-1.913986</td>\n",
       "      <td>2.112375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274877</td>\n",
       "      <td>-0.318597</td>\n",
       "      <td>0.073323</td>\n",
       "      <td>-0.061693</td>\n",
       "      <td>0.547204</td>\n",
       "      <td>-0.466798</td>\n",
       "      <td>0.408030</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-1.255549</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>52</td>\n",
       "      <td>1.147369</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>1.211023</td>\n",
       "      <td>-0.044096</td>\n",
       "      <td>0.301067</td>\n",
       "      <td>-0.132960</td>\n",
       "      <td>0.227885</td>\n",
       "      <td>0.252191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255924</td>\n",
       "      <td>-0.087813</td>\n",
       "      <td>-0.110756</td>\n",
       "      <td>-0.097771</td>\n",
       "      <td>-0.323374</td>\n",
       "      <td>0.633279</td>\n",
       "      <td>-0.305328</td>\n",
       "      <td>0.027394</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>67</td>\n",
       "      <td>-0.653445</td>\n",
       "      <td>0.160225</td>\n",
       "      <td>1.592256</td>\n",
       "      <td>1.296832</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>-0.343000</td>\n",
       "      <td>0.469937</td>\n",
       "      <td>-0.132470</td>\n",
       "      <td>-0.197794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225920</td>\n",
       "      <td>0.038363</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.102959</td>\n",
       "      <td>-0.265322</td>\n",
       "      <td>-0.348637</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>-0.049478</td>\n",
       "      <td>19.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "215   142  1.211406  0.007850  0.950798  1.137646 -0.495189  0.301371   \n",
       "166   105  1.175094  0.408263  0.552145  1.255068 -0.196662 -0.565605   \n",
       "241   162  1.039964 -0.534355  1.865190  1.145122 -1.488133  0.589641   \n",
       "225   147 -2.687978  4.390230 -2.360483  0.360829  1.310192 -1.645253   \n",
       "175   112  1.102698  0.103965  0.934479  1.152704 -0.693597 -0.584580   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "23     18  0.247491  0.277666  1.185471 -0.092603 -1.314394 -0.150116   \n",
       "113    74  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "132    83 -1.864990  0.910874  1.724863 -1.748371  0.578943 -0.832531   \n",
       "81     52  1.147369  0.059035  0.263632  1.211023 -0.044096  0.301067   \n",
       "97     67 -0.653445  0.160225  1.592256  1.296832  0.997175 -0.343000   \n",
       "\n",
       "           V7        V8        V9  ...       V20       V21       V22  \\\n",
       "215 -0.518350  0.095426  0.817592  ... -0.049912 -0.107248 -0.057153   \n",
       "166  0.133973 -0.146202 -0.214155  ... -0.116439  0.130585  0.523640   \n",
       "241 -1.119900  0.382781  1.419160  ... -0.053880 -0.014701  0.430843   \n",
       "225  2.327776 -1.727825  4.324752  ...  3.169344 -1.045961 -0.156951   \n",
       "175 -0.148439 -0.112031  0.196750  ...  0.037095 -0.017211 -0.098781   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "23  -0.946365 -1.617935  1.544071  ... -0.230983  1.650180  0.200454   \n",
       "113 -0.036715  0.350995  0.118950  ... -0.335520  0.102520  0.605089   \n",
       "132  1.901440 -1.913986  2.112375  ...  0.274877 -0.318597  0.073323   \n",
       "81  -0.132960  0.227885  0.252191  ... -0.255924 -0.087813 -0.110756   \n",
       "97   0.469937 -0.132470 -0.197794  ...  0.225920  0.038363  0.336449   \n",
       "\n",
       "          V23       V24       V25       V26       V27       V28  Amount  \n",
       "215 -0.118933 -0.421241  0.556146 -0.360164  0.076930  0.031800    9.99  \n",
       "166 -0.050125  0.448133  0.597867 -0.275067  0.043308  0.023924    1.00  \n",
       "241 -0.071344  0.638434  0.366778  0.451211  0.053840  0.023451   22.00  \n",
       "225  0.079854 -0.012598  0.207194 -0.536578  0.950393 -0.624431    0.89  \n",
       "175  0.003331  0.394412  0.334208 -0.520700  0.045952  0.048005   54.99  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "23  -0.185353  0.423073  0.820591 -0.227632  0.336634  0.250475   22.75  \n",
       "113  0.023092 -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18  \n",
       "132 -0.061693  0.547204 -0.466798  0.408030 -2.377933 -1.255549    7.69  \n",
       "81  -0.097771 -0.323374  0.633279 -0.305328  0.027394 -0.000580    6.67  \n",
       "97  -0.014883  0.102959 -0.265322 -0.348637  0.011238 -0.049478   19.85  \n",
       "\n",
       "[140 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad56a3",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d77de",
   "metadata": {},
   "source": [
    "### model - 1 random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce8343c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b138637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9783748361730014]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier object\n",
    "m1 = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s1, y_s1)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s1 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s1))\n",
    "m1_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b598e8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9783748361730014, 0.9750982961992136]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier object\n",
    "m1 = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s2, y_s2)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s2 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s2))\n",
    "m1_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea06b692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9783748361730014, 0.9750982961992136, 0.9678899082568807]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 3\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier object\n",
    "m1 = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s3, y_s3)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s3 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s3))\n",
    "m1_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f927e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9783748361730014,\n",
       " 0.9750982961992136,\n",
       " 0.9678899082568807,\n",
       " 0.5052424639580603]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 4\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier object\n",
    "m1 = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s4, y_s4)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s4 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s4))\n",
    "m1_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec2d51",
   "metadata": {},
   "source": [
    "### model - 2 logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2571bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a0c69732",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9141546526867628]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# train the model\n",
    "m2 = LogisticRegression()\n",
    "m2.fit(x_s1, y_s1)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe689b29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9141546526867628, 0.8951507208387942]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# train the model\n",
    "m2 = LogisticRegression()\n",
    "m2.fit(x_s2, y_s2)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8dfba07f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9141546526867628, 0.8951507208387942, 0.8971166448230669]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smaple 3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# train the model\n",
    "m2 = LogisticRegression()\n",
    "m2.fit(x_s3, y_s3)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0982ca9a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9141546526867628, 0.8951507208387942, 0.8971166448230669, 0.562254259501966]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 4\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# train the model\n",
    "m2 = LogisticRegression()\n",
    "m2.fit(x_s4, y_s4)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35323483",
   "metadata": {},
   "source": [
    "### model - 3 ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7307892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "719db4d9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9442988204456094]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 1\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "# Create an AdaBoost classifier\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "# Fit the AdaBoost classifier to the training data\n",
    "boost.fit(x_s1, y_s1)\n",
    "\n",
    "y_pred = boost.predict(x_smote)\n",
    "m3_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56b23b3b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9442988204456094, 0.9672346002621232]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 2\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "# Create an AdaBoost classifier\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "# Fit the AdaBoost classifier to the training data\n",
    "boost.fit(x_s2, y_s2)\n",
    "\n",
    "y_pred = boost.predict(x_smote)\n",
    "m3_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3bbf1537",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9442988204456094, 0.9672346002621232, 0.9521625163826999]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 3\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "# Create an AdaBoost classifier\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "# Fit the AdaBoost classifier to the training data\n",
    "boost.fit(x_s3, y_s3)\n",
    "\n",
    "y_pred = boost.predict(x_smote)\n",
    "m3_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m3_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8b775b87",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9442988204456094,\n",
       " 0.9672346002621232,\n",
       " 0.9521625163826999,\n",
       " 0.5111402359108781]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 4\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "# Create an AdaBoost classifier\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "# Fit the AdaBoost classifier to the training data\n",
    "boost.fit(x_s4, y_s4)\n",
    "\n",
    "y_pred = boost.predict(x_smote)\n",
    "m3_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51a562",
   "metadata": {},
   "source": [
    "### model - 4 XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "99fd0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a44e7e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9429882044560943]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 1\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s1,y_s1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f32e7672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9429882044560943, 0.9272608125819135]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 2\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s2,y_s2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ff10255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9429882044560943, 0.9272608125819135, 0.9423328964613368]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 3\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s3,y_s3)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f16c688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9429882044560943,\n",
       " 0.9272608125819135,\n",
       " 0.9423328964613368,\n",
       " 0.5131061598951507]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 4\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s4,y_s4)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0401a8",
   "metadata": {},
   "source": [
    "### model - 5 baggin classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0471748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "59b76b18",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9606815203145478]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample1\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Create an instance of the BaggingClassifier\n",
    "bagging = BaggingClassifier(base_estimator=dt, n_estimators=50)\n",
    "\n",
    "# Fit the model to the training data\n",
    "bagging.fit(x_s1, y_s1)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = bagging.predict(x_smote)\n",
    "\n",
    "# Evaluate the performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "m5_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c1abc51e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9606815203145478, 0.9311926605504587]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample2\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Create an instance of the BaggingClassifier\n",
    "bagging = BaggingClassifier(base_estimator=dt, n_estimators=50)\n",
    "\n",
    "# Fit the model to the training data\n",
    "bagging.fit(x_s2, y_s2)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = bagging.predict(x_smote)\n",
    "\n",
    "# Evaluate the performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "m5_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6a8bd8b0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9606815203145478, 0.9311926605504587, 0.9318479685452162]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample3\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Create an instance of the BaggingClassifier\n",
    "bagging = BaggingClassifier(base_estimator=dt, n_estimators=50)\n",
    "\n",
    "# Fit the model to the training data\n",
    "bagging.fit(x_s3, y_s3)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = bagging.predict(x_smote)\n",
    "\n",
    "# Evaluate the performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "m5_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7c90e62",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabhhandoo/miniforge3/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9606815203145478,\n",
       " 0.9311926605504587,\n",
       " 0.9318479685452162,\n",
       " 0.4980340760157274]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample4\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Create an instance of the BaggingClassifier\n",
    "bagging = BaggingClassifier(base_estimator=dt, n_estimators=50)\n",
    "\n",
    "# Fit the model to the training data\n",
    "bagging.fit(x_s4, y_s4)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = bagging.predict(x_smote)\n",
    "\n",
    "# Evaluate the performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "m5_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc4676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24320cf6",
   "metadata": {},
   "source": [
    "# Comparing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "26e3e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp=pd.DataFrame(data=[m1_acc,m2_acc,m3_acc,m4_acc,m5_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c32364ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978375</td>\n",
       "      <td>0.975098</td>\n",
       "      <td>0.967890</td>\n",
       "      <td>0.505242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.895151</td>\n",
       "      <td>0.897117</td>\n",
       "      <td>0.562254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944299</td>\n",
       "      <td>0.967235</td>\n",
       "      <td>0.952163</td>\n",
       "      <td>0.511140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942988</td>\n",
       "      <td>0.927261</td>\n",
       "      <td>0.942333</td>\n",
       "      <td>0.513106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960682</td>\n",
       "      <td>0.931193</td>\n",
       "      <td>0.931848</td>\n",
       "      <td>0.498034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.978375  0.975098  0.967890  0.505242\n",
       "1  0.914155  0.895151  0.897117  0.562254\n",
       "2  0.944299  0.967235  0.952163  0.511140\n",
       "3  0.942988  0.927261  0.942333  0.513106\n",
       "4  0.960682  0.931193  0.931848  0.498034"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "02947a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.index=[\"Random forest\",\"Logistic Regression\",\"adaBoost\",\"XGBoost\",\"Bagging Classifier\"]\n",
    "comp.columns=[\"Random\",\"Systematic\",\"Stratified\",\"Clustering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dcf2054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random</th>\n",
       "      <th>Systematic</th>\n",
       "      <th>Stratified</th>\n",
       "      <th>Clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.978375</td>\n",
       "      <td>0.975098</td>\n",
       "      <td>0.967890</td>\n",
       "      <td>0.505242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.895151</td>\n",
       "      <td>0.897117</td>\n",
       "      <td>0.562254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaBoost</th>\n",
       "      <td>0.944299</td>\n",
       "      <td>0.967235</td>\n",
       "      <td>0.952163</td>\n",
       "      <td>0.511140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.942988</td>\n",
       "      <td>0.927261</td>\n",
       "      <td>0.942333</td>\n",
       "      <td>0.513106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.960682</td>\n",
       "      <td>0.931193</td>\n",
       "      <td>0.931848</td>\n",
       "      <td>0.498034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Random  Systematic  Stratified  Clustering\n",
       "Random forest        0.978375    0.975098    0.967890    0.505242\n",
       "Logistic Regression  0.914155    0.895151    0.897117    0.562254\n",
       "adaBoost             0.944299    0.967235    0.952163    0.511140\n",
       "XGBoost              0.942988    0.927261    0.942333    0.513106\n",
       "Bagging Classifier   0.960682    0.931193    0.931848    0.498034"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
